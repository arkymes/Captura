import os
import re
import json
import sys
from pathlib import Path
from typing import Optional, Callable
import base64
import tempfile
import shutil
import streamlit as st
import streamlit.components.v1 as components
from google import genai
from google.genai import types
from google.genai import errors as genai_errors

# Adicionar diret√≥rio raiz ao path para imports
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from Captura.utils.models import models as internal_models
from Captura.utils.layout_config import LayoutConfig, show_layout_config_modal
import subprocess
import sys
import time


APP_TITLE = "Captura"
MODEL_ID = "gemini-2.5-pro"


# ===============================
# UI helpers
# ===============================

def _init_session_state():
    if "show_help" not in st.session_state:
        st.session_state.show_help = False
    if "generated_md" not in st.session_state:
        st.session_state.generated_md = ""
    if "last_saved_path" not in st.session_state:
        st.session_state.last_saved_path = ""
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []  # list[{role: 'user'|'ia', 'text': str}]
    if "input_video_path" not in st.session_state:
        st.session_state.input_video_path = ""
    if "last_docx_b64" not in st.session_state:
        st.session_state.last_docx_b64 = ""
    if "last_docx_name" not in st.session_state:
        st.session_state.last_docx_name = "index.docx"
    if "last_docx_bytes" not in st.session_state:
        st.session_state.last_docx_bytes = b""
    if "download_data_url" not in st.session_state:
        st.session_state.download_data_url = ""
    if "extra_notes" not in st.session_state:
        st.session_state.extra_notes = ""
    if "trigger_download" not in st.session_state:
        st.session_state.trigger_download = False
    if "doc_elaboracao" not in st.session_state:
        st.session_state.doc_elaboracao = ""
    if "doc_aprovacao" not in st.session_state:
        st.session_state.doc_aprovacao = ""
    if "internal_template_key" not in st.session_state:
        st.session_state.internal_template_key = "model_rpa"
    if "custom_template_text" not in st.session_state:
        st.session_state.custom_template_text = ""
    if "custom_template_source_name" not in st.session_state:
        st.session_state.custom_template_source_name = ""
    if "layout_modal_open" not in st.session_state:
        st.session_state.layout_modal_open = False
    if "layout_feedback" not in st.session_state:
        st.session_state.layout_feedback = ""
    if "layout_loaded_from_local" not in st.session_state:
        st.session_state.layout_loaded_from_local = False
    if "layout_initializing" not in st.session_state:
        st.session_state.layout_initializing = False
    if "layout_load_attempts" not in st.session_state:
        st.session_state.layout_load_attempts = 0


def _trigger_rerun() -> None:
    rerun_fn = getattr(st, "rerun", None)
    if callable(rerun_fn):
        rerun_fn()
    else:
        st.experimental_rerun()


def _render_layout_config_body(workdir: Path, key_suffix: str) -> None:
    show_layout_config_modal()
    st.markdown("---")
    action_cols = st.columns(2)
    if action_cols[0].button("Salvar altera√ß√µes", key=f"layout_save_button{key_suffix}"):
        # Salvar somente no navegador (localStorage)
        try:
            from Captura.utils.layout_config import LayoutConfig as _LC  # updated path after move
            _LC.save_current_to_local_storage()
            st.session_state.layout_feedback = "Configura√ß√£o de layout salva no navegador."
        except Exception:
            st.session_state.layout_feedback = "N√£o foi poss√≠vel salvar no navegador."
        st.session_state.layout_modal_open = False
        _trigger_rerun()
    if action_cols[1].button("Fechar", key=f"layout_close_button{key_suffix}"):
        st.session_state.layout_modal_open = False
        _trigger_rerun()


def _build_few_shot_history(example_text: str, example_template: str, source_text: str) -> list:
    """
    Constr√≥i um hist√≥rico de 3 turnos (few-shot learning) para ensinar ao Gemini o padr√£o:
    
    Turno 3: Usu√°rio envia o novo arquivo para processar
    
    Isso for√ßa o Gemini a reconhecer o padr√£o (arquivo -> classe Python) 
    em vez de copiar o exemplo.
    """
    
    # Turno 3: Usu√°rio (Tarefa real - o novo arquivo)
    turn_3_user = types.Content(
        role="user",
        parts=[types.Part.from_text(text=source_text)]
    )
    # Por enquanto retornamos somente o turno atual (o exemplo pr√©vio foi removido
    # em refatora√ß√£o anterior). Expandir no futuro se quisermos few-shot completo.
    return [turn_3_user]


def _inject_css():
    # Minimal, modern styles for help icon and modal (dark theme)
    st.markdown(
        """
        <style>
        /* Wrap for the small icon button next to API key */
        .help-btn button {
            width: 36px; height: 36px; border-radius: 999px;
            border: 1px solid #374151; background-color: #1f2937; color: #e5e7eb;
            background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="%23e5e7eb" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"/><line x1="12" y1="17" x2="12.01" y2="17"/></svg>');
            background-repeat: no-repeat; background-position: center; cursor: pointer;
        }
        .help-btn button:hover { background-color: #111827; border-color: #4b5563; }

        /* Dark modal */
        .gmodal-overlay { position: fixed; inset: 0; background: rgba(0,0,0,.65); z-index: 1000; }
        .gmodal { position: fixed; top: 6%; left: 50%; transform: translateX(-50%);
                  width: min(900px, 94%); max-height: 86vh; overflow: auto; background: #0f172a;
                  color: #e5e7eb; border-radius: 12px; padding: 22px 26px; z-index: 1001;
                  box-shadow: 0 10px 30px rgba(0,0,0,.35); border: 1px solid #1f2937;
        }
        .gmodal h2 { margin-top: 0; font-weight: 600; letter-spacing: .2px; }
        .gmodal p, .gmodal li { line-height: 1.5; font-size: 0.97rem; }
        .gmodal ol { padding-left: 22px; }
        .gmodal .close { position: absolute; top: 10px; right: 14px; font-size: 22px; cursor: pointer; color: #9ca3af; }
        .gmodal .close:hover { color: #e5e7eb; }
        .gmodal .hint { background: #0b1220; border: 1px solid #1f2937; padding: 12px 14px; border-radius: 8px; }
        .gmodal a { color: #93c5fd; text-decoration: none; }
        .gmodal a:hover { text-decoration: underline; }
        </style>
        """,
        unsafe_allow_html=True,
    )


def _help_modal():
    if not st.session_state.show_help:
        return

    body = """
    <div class=\"gmodal-overlay\"></div>
    <div class=\"gmodal\">
      <div class=\"close\" onclick=\"window.parent.dispatchEvent(new Event('close-help'))\">‚úñ</div>
      <h2>Como obter sua chave da API do Gemini</h2>
      <p>Para gerar a documenta√ß√£o com IA, voc√™ precisa de uma API Key do Google AI Studio (Gemini).</p>
      <ol>
        <li>Acesse <a href=\"https://aistudio.google.com/api-keys\" target=\"_blank\">https://aistudio.google.com/api-keys</a>.</li>
        <li>Fa√ßa login com sua conta Google e conclua a verifica√ß√£o se solicitado.</li>
        <li>Clique em ‚ÄúCreate API key‚Äù (Criar chave de API) e escolha ‚ÄúPersonal use‚Äù.</li>
        <li>Copie a chave exibida e cole no campo ‚ÄúGemini API Key‚Äù na barra lateral deste app.</li>
      </ol>
      <div class=\"hint\">
        Dica: guarde sua chave com seguran√ßa. Voc√™ pode revog√°-la ou criar uma nova quando quiser, na mesma p√°gina.
      </div>
      <p style=\"margin-top: 14px;\">Caso prefira um passo a passo ilustrado, abra o link e siga as instru√ß√µes na pr√≥pria p√°gina.</p>
    </div>
    <script>
      window.addEventListener('close-help', () => { /* noop */ });
    </script>
    """

    st.markdown(body, unsafe_allow_html=True)
    # Bot√£o de fechar (server-side)
    st.button("Fechar ajuda", on_click=lambda: st.session_state.update({"show_help": False}))


# ===============================
# Gemini interaction
# ===============================

def _normalize_file_state(state_obj) -> str:
    """Return a normalized file state label like 'ACTIVE', 'FAILED', 'PROCESSING'.
    Handles enums (with .name), plain strings like 'FileState.ACTIVE', or unknown values.
    """
    try:
        if hasattr(state_obj, "name"):
            name = state_obj.name
        else:
            name = str(state_obj or "")
        if not name:
            return ""
        # Keep only the segment after the last dot, e.g. 'FileState.ACTIVE' -> 'ACTIVE'
        if "." in name:
            name = name.split(".")[-1]
        return name.upper()
    except Exception:
        return ""

def _detect_mime(filename: str, fallback: str = "application/octet-stream") -> str:
    name = (filename or "").lower()
    if name.endswith(".mp4"): return "video/mp4"
    if name.endswith(".mov"): return "video/quicktime"
    if name.endswith(".avi"): return "video/x-msvideo"
    if name.endswith(".mkv"): return "video/x-matroska"
    if name.endswith(".webm"): return "video/webm"
    if name.endswith(".vtt"): return "text/vtt"
    if name.endswith(".txt"): return "text/plain"
    return fallback


def _safe_extract_text(resp) -> str:
    """Extract aggregated text from a non-streaming Gemini response."""
    try:
        if getattr(resp, "text", None):
            return resp.text
        # Fallback: concatenate candidate parts
        texts = []
        for cand in getattr(resp, "candidates", []) or []:
            content = getattr(cand, "content", None)
            parts = getattr(content, "parts", []) if content else []
            for p in parts:
                t = getattr(p, "text", None)
                if t:
                    texts.append(t)
        return "".join(texts)
    except Exception:
        return ""


def _clean_markdown_response(text: str) -> str:
    """Remove only a top-level wrapping markdown code fence, preserving inline fences like ```mermaid.

    Context: Some LLMs wrap the entire document in ```markdown ... ```. We want to strip ONLY this
    outer wrapper if present at the very start/end of the document, and never touch inner code blocks
    such as ```mermaid or regular ```code snippets embedded in the content.
    """
    if not text:
        return ""

    # Normalize newlines for consistent matching
    s = text

    # Match a code fence at the very beginning of the document, with optional language.
    # We only remove it if the language is empty or explicitly markdown/md.
    m = re.match(r"^(\s*)```([A-Za-z0-9_+-]+)?\s*\n", s)
    if m:
        leading_ws, lang = m.group(1), (m.group(2) or "").lower()
        if lang in ("", "markdown", "md"):
            s = s[m.end():]
            # Remove a final fence only if nothing but whitespace precedes it
            s = re.sub(r"\n```\s*$", "", s)
        else:
            # Not a markdown wrapper; leave intact
            return s.strip()

    # Do NOT remove other ``` fences (like ```mermaid) elsewhere.
    return s.strip()


def build_system_instruction() -> str:
    """Instru√ß√µes do sistema para a gera√ß√£o do .md no padr√£o R004.

    Mant√©m as regras principais: estrutura, placeholders de PRINT com HH:MM:SS obtidos do v√≠deo,
    estilo e proibi√ß√µes. Responder somente com o conte√∫do do arquivo .md completo.
    """
    # Base system instruction relies on selected or custom template appended at runtime.
    return (
        "Voc√™ √© uma IA especializada em criar documenta√ß√µes operacionais no formato padr√£o ou em um modelo customizado fornecido. "
        "Transforme o v√≠deo (e opcionalmente a transcri√ß√£o) em um documento Markdown (.md) completo.\n\n"
        "IMPORTANTE - REGRAS DE FORMATA√á√ÉO DO MARKDOWN:\n"
        "1. Comece DIRETAMENTE com o conte√∫do. N√ÉO coloque ```markdown no in√≠cio.\n"
        "2. Use APENAS um # para t√≠tulo principal (# T√≠tulo), n√£o ##.\n"
        "3. Metadados no in√≠cio devem estar em formato limpo: **Chave:** valor (sem markdown code blocks).\n"
        "4. Se√ß√µes numeradas como: ## 1. OBJETIVO, ## 2. APLICA√á√ÉO, ## 3. REFER√äNCIAS, etc.\n"
        "5. Use ## para se√ß√µes principais, ### para subse√ß√µes.\n\n"
        "Responda APENAS com o .md completo, sem coment√°rios adicionais ou blocos de c√≥digo.\n\n"
        "Regras principais inegoci√°veis:\n"
        "- Preserve exatamente a estrutura e se√ß√µes do modelo de refer√™ncia fornecido abaixo.\n"
        "- Placeholders obrigat√≥rios no formato: [PRINT DO V√çDEO - HH:MM:SS: Descri√ß√£o...] (se necess√°rio e assim pedir o modelo)\n"
        "- N√£o inventar dados inexistentes; use [Informa√ß√£o n√£o dispon√≠vel no v√≠deo] quando algo n√£o estiver vis√≠vel.\n"
        "- Proibido usar a palavra 'citestart'.\n\n"
        "Modelo de refer√™ncia (N√ÉO repetir explica√ß√µes; apenas siga a estrutura):\n"
    )


def run_generation(api_key: str,
                   video_name: str,
                   video_mime: str,
                   *,
                   video_path: Optional[Path] = None,
                   video_bytes: Optional[bytes] = None,
                   video_size_mb: Optional[float] = None,
                   transcript_name: Optional[str] = None,
                   transcript_bytes: Optional[bytes] = None,
                   transcript_mime: Optional[str] = None,
                   progress: Optional[Callable[[str], None]] = None,
                   extra_notes: Optional[str] = None,
                   active_template_text: Optional[str] = None) -> str:
    client = genai.Client(api_key=api_key)

    parts = []  # type: ignore[var-annotated]

    # V√≠deo (obrigat√≥rio): preferir upload para Files API para evitar payloads grandes
    video_part = None
    if video_path and Path(video_path).exists():
        try:
            uploaded = client.files.upload(
                file=str(video_path),
                config=types.UploadFileConfig(mime_type=video_mime),
            )
            # Aguardar at√© o arquivo ficar ACTIVE antes de usar
            try:
                # Ajusta o tempo m√°ximo com base no tamanho do v√≠deo (se conhecido)
                max_wait = 600 if (video_size_mb or 0) > 300 else 300
                deadline = time.time() + max_wait
                sleep_s = 1.5
                current = uploaded
                while True:
                    state = _normalize_file_state(getattr(current, "state", None))
                    if progress:
                        elapsed = int((max_wait - max(0, deadline - time.time())))
                        progress(f"Aguardando processamento do v√≠deo na IA‚Ä¶ estado={state or 'DESCONHECIDO'} | {elapsed}s de {max_wait}s")
                    if state == "ACTIVE":
                        break
                    if state in {"FAILED", "ERROR"}:
                        raise RuntimeError(f"Arquivo de v√≠deo falhou no processamento da IA (estado: {state}).")
                    if time.time() > deadline:
                        raise TimeoutError("Timeout aguardando o arquivo de v√≠deo ficar ACTIVE na IA.")
                    time.sleep(sleep_s)
                    # Tentar atualizar o estado
                    name = getattr(current, "name", None) or getattr(current, "id", None)
                    if name and not str(name).startswith("files/"):
                        name = f"files/{name}"
                    try:
                        current = client.files.get(name=name) if name else current
                    except Exception as e:
                        if progress:
                            progress(f"Falha ao obter status do arquivo de v√≠deo: {e}")
                uploaded = current
            except Exception as ex:
                # N√£o usar a URI se n√£o tivermos ACTIVE
                if progress:
                    progress(f"Falha ao aguardar processamento do v√≠deo: {ex}. Tentando fallback por bytes‚Ä¶")
                uploaded = None
            # Usar URI apenas se ACTIVE
            if uploaded and _normalize_file_state(getattr(uploaded, 'state', None)) == 'ACTIVE' and getattr(uploaded, 'uri', None):
                video_part = types.Part.from_uri(file_uri=uploaded.uri, mime_type=video_mime)
        except Exception as e:
            if progress:
                progress(f"Falha ao usar URI do v√≠deo, tentando fallback por bytes‚Ä¶: {e}")
            video_part = None
    if video_part is None:
        # Fallback: enviar bytes (pode falhar com v√≠deos grandes)
        if not video_bytes:
            # Como √∫ltimo recurso, tente ler do path
            try:
                video_bytes = Path(video_path).read_bytes() if video_path else None
            except Exception:
                video_bytes = None
        if not video_bytes:
            raise RuntimeError("N√£o foi poss√≠vel preparar o v√≠deo para a IA.")
        video_part = types.Part.from_bytes(data=video_bytes, mime_type=video_mime)
    parts.append(video_part)

    # Transcri√ß√£o (opcional)
    transcript_text: Optional[str] = None
    if transcript_bytes:
        # Para maior compatibilidade, converter para texto quando poss√≠vel
        try:
            transcript_text = transcript_bytes.decode("utf-8", errors="ignore")
        except Exception as e:
            transcript_text = None

    if transcript_text:
        parts.append(types.Part.from_text(text=(
            f"Transcri√ß√£o auxiliar do v√≠deo ({transcript_name or 'transcript'}):\n\n" + transcript_text
        )))
    elif transcript_bytes and transcript_mime:
        parts.append(types.Part.from_bytes(data=transcript_bytes, mime_type=transcript_mime))

    # Build user prompt incorporating active template reference
    template_ref = (active_template_text or getattr(internal_models, st.session_state.internal_template_key, "")).strip()
    user_prompt = (
        f"Video de entrada: {video_name}\n"
        f"Transcri√ß√£o: {transcript_name or 'n√£o fornecida'}\n\n"
        "Gere o .md seguindo estritamente o modelo de refer√™ncia fornecido abaixo.\n"
        "Modelo de refer√™ncia (n√£o repetir linha explicativa):\n\n"
        f"{template_ref}\n\n"
        "Lembre-se de incluir os placeholders de PRINT com timestamps do v√≠deo."
    )
    if extra_notes:
        user_prompt += (
            "\n\nInforma√ß√µes adicionais fornecidas pelo usu√°rio (priorize integrar ao conte√∫do quando relevante):\n"
            f"{extra_notes}"
        )

    contents = [
        types.Content(
            role="user",
            parts=parts + [types.Part.from_text(text=user_prompt)],
        )
    ]

    cfg = types.GenerateContentConfig(
        temperature=0.65,
        thinking_config=types.ThinkingConfig(thinking_budget=-1),
        system_instruction=[
            types.Part.from_text(text="""
Sempre responder APENAS com o arquivo.md da documenta√ß√£o e nada mais


[Coisas MUITO IMPORTANTES a se atentar e seguir √† risca:]
--N√ÉO COLOCAR TIMESTAMPS ALEAT√ìRIOS FORA DOS PLACEHOLDERS, POR EXEMPLO: Clicar em \"Entrar\" para acessar o ambiente Financeiro (10:23).
--N√ÉO COLOCAR PLACEHOLDERS COM ERROS, POR EXEMPLO: [Informa√ß√£o n√£o dispon√≠vel no v√≠deo].
--N√ÉO √â PARA REFERENCIAR O VIDEO DE MANEIRA ALGUMA FORA DOS PLACEHOLDERS! Ou seja, N√ÉO COLOCAR FRASES TIPO: \"No v√≠deo, √†s 02:15, vemos que...\".
[/Coisas MUITO IMPORTANTES a se atentar e seguir √† risca:]



Entradas

Arquivo de v√≠deo original (obrigat√≥rio).

Transcri√ß√£o (opcional ‚Äî use apenas como aux√≠lio ao identificar di√°logos; N√ÉO baseie minutagem nos hor√°rios da transcri√ß√£o).

Metadados opcionais: nome do processo, departamento, respons√°vel, data, vers√£o.

Regras essenciais (leia com aten√ß√£o)

Estrutura do documento deve ser id√™ntica ao modelo:
N√£o inventar informa√ß√µes: se um detalhe n√£o estiver vis√≠vel no v√≠deo (ex.: credenciais ocultas, popups que n√£o aparecem), marque [Informa√ß√£o n√£o dispon√≠vel no v√≠deo] no local apropriado.

Proibi√ß√£o de termo: n√£o escrever a palavra citestart em nenhuma parte do resultado.

Formato e estilo: linguagem clara e t√©cnica, termos padronizados, t√≠tulos exatamente iguais ao modelo R004, listas com marcadores e numera√ß√£o (1., 2., 2.1. etc.). Use frases curtas e instru√ß√µes imperativas.

Sa√≠da obrigat√≥ria

Gere um arquivo Markdown (.md) contendo o documento completo no formato o .md deve incluir todos os placeholders de prints no corpo do documento.

{modelo_documento}"""),
        ],
    )
    

    # Gera√ß√£o com resili√™ncia: tenta streaming e faz fallback para n√£o-stream se a conex√£o cair
    if progress:
        progress("2/3 ‚Ä¢ Gerando o .md com a IA‚Ä¶")
    output_md = []
    stream_error = None
    try:
        last_yield = time.time()
        total = 0
        for chunk in client.models.generate_content_stream(
            model=MODEL_ID,
            contents=contents,
            config=cfg,
        ):
            if getattr(chunk, "text", None):
                t = chunk.text
                output_md.append(t)
                total += len(t)
                if progress and (time.time() - last_yield) >= 1.0:
                    progress(f"IA gerando o .md (stream)‚Ä¶ {total} caracteres recebidos")
                    last_yield = time.time()
    except Exception as e:
        stream_error = e
        if progress:
            progress(f"Conex√£o do stream caiu: {e}. Tentando modo sem streaming‚Ä¶")

    if stream_error is not None and not output_md:
        # Fallback: chamada n√£o-streaming
        try:
            if progress:
                progress("IA gerando o .md (modo n√£o-streaming)...")
            resp = client.models.generate_content(
                model=MODEL_ID,
                contents=contents,
                config=cfg,
            )
            text = _safe_extract_text(resp)
            if not text:
                raise RuntimeError("Resposta vazia da IA (modo n√£o-streaming).")
            return _clean_markdown_response(text)
        except Exception as e2:
            raise RuntimeError(f"Falha ao gerar conte√∫do (fallback): {e2}") from stream_error

    return _clean_markdown_response("".join(output_md))


def _get_output_dir() -> Path:
    # Ap√≥s reorganiza√ß√£o: base do projeto √© o diret√≥rio pai de Captura
    return Path(__file__).resolve().parent.parent


def _auto_download_docx(name: str, data: bytes) -> str:
        """Dispara download autom√°tico via HTML invis√≠vel; retorna data URL para fallback."""
        b64 = base64.b64encode(data).decode("ascii")
        data_url = f"data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}"
        html = f"""
        <html>
            <body>
                <a id=\"auto_dl_link\" href=\"{data_url}\" download=\"{name}\"></a>
                <script>
                    const link = document.getElementById('auto_dl_link');
                    if (link) {{
                            setTimeout(() => link.click(), 200);
                    }}
                </script>
            </body>
        </html>
        """
        components.html(html, height=0, width=0)
        return data_url


def _write_doc_metadata(base_dir: Path, elaboracao: str, aprovacao: str) -> None:
    meta_path = base_dir / "doc_meta.json"
    data = {}
    if elaboracao:
        data["elaboracao"] = elaboracao
    if aprovacao:
        data["aprovacao"] = aprovacao

    try:
        if data:
            meta_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
        elif meta_path.exists():
            meta_path.unlink()
    except Exception as exc:  # noqa: BLE001
        st.warning(f"N√£o foi poss√≠vel atualizar o arquivo de metadados: {exc}")


def _sanitize_filename(name: str) -> str:
    # Remove caracteres inv√°lidos para filename no Windows
    name = re.sub(r"[\\/:*?\"<>|]+", " ", name).strip()
    return name or "documento.md"


# ===============================
# App (Streamlit)
# ===============================

def main():
    # Carregar √≠cone em .ico para a janela
    icon_path = Path(__file__).resolve().parent / "icon" / "captura_icon.ico"
    st.set_page_config(page_title=APP_TITLE, page_icon=icon_path if icon_path.exists() else "üß†", layout="wide")
    _init_session_state()
    LayoutConfig.init_session_state()
    workdir = Path(__file__).resolve().parent
    # Carregar automaticamente do localStorage (uma vez)
    # Tentar carregar do localStorage em cada primeira execu√ß√£o at√© conseguir (streamlit_js_eval retorna na segunda rodada)
    if not st.session_state.layout_loaded_from_local:
        st.session_state.layout_load_attempts += 1
        loaded = False
        try:
            loaded = LayoutConfig.load_from_local_storage_into_session()
        except Exception:
            loaded = False
        if loaded:
            st.session_state.layout_loaded_from_local = True
            st.session_state.layout_initializing = False
            _trigger_rerun()
        else:
            # Primeiro ciclo: marcar como inicializando e for√ßar segundo ciclo para tentar novamente
            if st.session_state.layout_load_attempts == 1:
                st.session_state.layout_initializing = True
                _trigger_rerun()
            # Ap√≥s 3 tentativas desistimos e limpamos estado de inicializa√ß√£o
            elif st.session_state.layout_load_attempts >= 3:
                st.session_state.layout_initializing = False
    
    _inject_css()

    # Cabe√ßalho com √≠cone e t√≠tulo
    col_icon, col_title = st.columns([0.08, 0.92])
    with col_icon:
        icon_png_path = Path(__file__).resolve().parent / "icon" / "captura_icon.png"
        if icon_png_path.exists():
            st.image(str(icon_png_path), width=60)
    with col_title:
        st.title(APP_TITLE)

    if st.session_state.layout_feedback:
        st.markdown(f"{st.session_state.layout_feedback}")
        st.session_state.layout_feedback = ""

    # (modal moved after sidebar)

    # Sidebar: Config
    with st.sidebar:
        st.subheader("Configura√ß√£o")
        if st.button("Configurar layout", key="layout_sidebar_button"):
            st.session_state.layout_modal_open = True
            _trigger_rerun()
        cols = st.columns([1, 0.2])
        with cols[0]:
            api_key = st.text_input("Gemini API Key", type="password", placeholder="AI.../AIza...")
        with cols[1]:
            st.write("")
            st.markdown('<div class="help-btn">', unsafe_allow_html=True)
            if st.button(" ", key="help_icon", help="Como obter a chave do Gemini"):
                st.session_state.show_help = True
            st.markdown('</div>', unsafe_allow_html=True)

        if api_key:
            os.environ["GEMINI_API_KEY"] = api_key

        st.markdown("---")
        st.subheader("Rodap√© do documento")
        st.text_input(
            "Elabora√ß√£o / Revis√£o",
            key="doc_elaboracao",
            placeholder="Respons√°vel pela elabora√ß√£o e data",
            help="Defina o texto que aparecer√° no campo 'Elabora√ß√£o/ Revis√£o' do rodap√© do DOCX.",
        )
        st.text_input(
            "Aprova√ß√£o",
            key="doc_aprovacao",
            placeholder="Respons√°vel pela aprova√ß√£o",
            help="Defina o texto que aparecer√° no campo 'Aprova√ß√£o' do rodap√© do DOCX.",
        )

        st.markdown("---")
        st.subheader("Modelo do Documento")
        # Gather available internal templates by reflecting over attributes that start with 'model_'
        internal_template_map = {
            name: getattr(internal_models, name)
            for name in dir(internal_models)
            if name.startswith("model_") and isinstance(getattr(internal_models, name), str)
        }
        template_keys = list(internal_template_map.keys())
        # Format display options: remove 'model_' prefix and convert to title case
        display_names = [key.replace("model_", "").replace("_", " ").title() for key in template_keys]
        options_display = display_names + ["Customizado"]
        # Map display names back to original keys for retrieval
        display_to_key = {display: key for display, key in zip(display_names, template_keys)}
        display_to_key["Customizado"] = "Customizado"
        
        # Get the current display name from stored key
        current_display = display_to_key.get(st.session_state.internal_template_key, None)
        if current_display is None and st.session_state.internal_template_key.startswith("model_"):
            current_display = st.session_state.internal_template_key.replace("model_", "").replace("_", " ").title()
        default_index = options_display.index(current_display) if current_display in options_display else 0
        
        selected_display = st.selectbox(
            "Selecionar modelo",
            options_display,
            index=default_index,
            help="Escolha um modelo interno ou selecione 'Customizado' para enviar um arquivo e gerar um modelo novo via agente separado."
        )
        # Map back to the actual template key
        st.session_state.internal_template_key = display_to_key[selected_display]

        if selected_display == "Customizado":
            st.caption("Envie um arquivo (.pdf ou .txt) para gerar um modelo customizado usando outro agente.")
            uploaded_custom_model = st.file_uploader("Arquivo de modelo (PDF ou TXT)", type=["pdf", "txt"], accept_multiple_files=False)
            generate_custom_model = st.button("Gerar modelo customizado")

            if generate_custom_model:
                # Show a minimal animated loader while processing
                loader = st.empty()
                loader.markdown(
                    """
                    <div style="display:flex;align-items:center;gap:10px;">
                        <div style="font-size:14px;opacity:0.85;">Gerando modelo customizado‚Ä¶</div>
                        <div class="dots-loader">
                            <span></span><span></span><span></span>
                        </div>
                    </div>
                    <style>
                        .dots-loader{display:inline-flex;gap:8px;}
                        .dots-loader span{width:10px;height:10px;background:#93c5fd;border-radius:50%;display:inline-block;animation:bounce 1s infinite ease-in-out;opacity:.85}
                        .dots-loader span:nth-child(2){animation-delay:.15s}
                        .dots-loader span:nth-child(3){animation-delay:.30s}
                        @keyframes bounce{0%,80%,100%{transform:translateY(0);opacity:.6}40%{transform:translateY(-8px);opacity:1}}
                    </style>
                    """,
                    unsafe_allow_html=True,
                )
                try:
                    if not uploaded_custom_model:
                        st.error("Envie um arquivo PDF ou TXT para gerar o modelo customizado.")
                    else:
                        raw_bytes = uploaded_custom_model.read()
                        source_text = ""
                        ext = uploaded_custom_model.name.lower().split('.')[-1]
                        try:
                            if ext == 'txt':
                                source_text = raw_bytes.decode('utf-8', errors='ignore')
                            elif ext == 'pdf':
                                try:
                                    import PyPDF2  # type: ignore
                                except Exception:
                                    st.error("Depend√™ncia PyPDF2 n√£o instalada. Adicione 'PyPDF2' ao requirements.txt.")
                                    source_text = ""
                                else:
                                    try:
                                        from io import BytesIO
                                        reader = PyPDF2.PdfReader(BytesIO(raw_bytes))
                                        pages_text = []
                                        for page in reader.pages:
                                            pages_text.append(page.extract_text() or "")
                                        source_text = "\n".join(pages_text)
                                    except Exception as pdf_exc:
                                        st.error(f"Falha ao extrair texto do PDF: {pdf_exc}")
                                        source_text = ""
                            else:
                                st.error("Formato n√£o suportado. Use PDF ou TXT.")
                        except Exception as ext_exc:
                            st.error(f"Falha ao ler arquivo: {ext_exc}")
                            source_text = ""

                        if source_text.strip():
                            # Build prompt for secondary agent
                            # Use a stable internal example (default to first key or model_rpa)
                            example_key = 'model_rpa' if 'model_rpa' in internal_template_map else (template_keys[0] if template_keys else '')
                            example_template = internal_template_map.get(example_key, "")
                            secondary_system = (
                                "Voc√™ √© uma IA especializada em normalizar modelos de documenta√ß√£o. "
                                "Analise o arquivo e gere UM NOVO MODELO com a mesma estrutura l√≥gica. \n"
                                "Responda apenas com o novo modelo em texto puro. N√£o inclua explica√ß√µes, apenas a estrutura e instru√ß√µes necess√°rias.\n"
                                "O modelo deve contar APENAS os 'cap√≠tulos' do arquivo original, n√£o adicione nada. \n"
                                "S√≥ incluir sub capitulos se eles puderem ser usados em qualquer outro documento. ou seja, N√ÉO INCLUA SUB CAP√çTULOS ESPEC√çFICOS.\n"
                                "Ou seja, N√ÉO COLOQUE NO MODELO NENHUMA INFORMA√á√ÉO ESPEF√çCICA DO ARQUIVO, APENAS CRIE UM MODELO GEN√âRICO COM A MESMA ESTRUTURA L√ìGICA!!.\n"
                                "DE MANEIRA ALGUMA COPIE OS CONTE√öDOS ESPEC√çFICOS DO ARQUIVO, APENAS A ESTRUTURA DE CAP√çTULOS E SE√á√ïES.\n"
                                "O Formato do modelo deve ser conforme abaixo abaixo:\n"
                                "[capitulos do modelo]\n"
                                "[Explica√ß√µes de cada campo do modelo]\n"
                                "[Instru√ß√µes GENERICAS de preenchimento do modelo]\n"
                                "[Instru√ß√µes de placeholder de PRINT do modelo]\n"
                                "[Exemplo do MD do modelo]\n"
                                "------------------------------------------------------------------------------------------------------------------------\n"

                            )
                            # Extrai texto de exemplo a partir de utils/model_rp.pdf
                            example_text = ""
                            try:
                                pdf_path = Path(__file__).resolve().parent / "utils" / "model_rp.pdf"
                                if pdf_path.exists():
                                    try:
                                        import PyPDF2  # type: ignore
                                    except Exception:
                                        st.error("Depend√™ncia PyPDF2 n√£o instalada. Adicione 'PyPDF2' ao requirements.txt.")
                                    else:
                                        try:
                                            with pdf_path.open("rb") as f:
                                                reader = PyPDF2.PdfReader(f)
                                                pages_text = []
                                                for i, page in enumerate(reader.pages):  # limita p√°ginas para evitar tokens demais
                                                    pages_text.append(page.extract_text() or "")
                                                example_text = "\n".join(pages_text).strip()
                                        except Exception as pdf_exc:
                                            st.error(f"Falha ao extrair texto de utils/model_rp.pdf: {pdf_exc}")
                                else:
                                    st.warning("Arquivo utils/model_rp.pdf n√£o encontrado. Usando o modelo interno como fallback.")
                            except Exception as exc:
                                st.warning(f"N√£o foi poss√≠vel obter texto do PDF de exemplo: {exc}")

      
                            # Build few-shot history (3 turns)
                            print(example_text)
                            print('=' *200)
                            print(example_template)
                            print('=' *200)
                            print(source_text)
                            contents_secondary = _build_few_shot_history(example_text, example_template, source_text)
                            
                            api_key_secondary = os.environ.get("GEMINI_API_KEY", "")
                            if not api_key_secondary:
                                st.error("Informe a Gemini API Key antes de gerar modelo customizado.")
                            else:
                                try:
                                    client_secondary = genai.Client(api_key=api_key_secondary)
                                    cfg_secondary = types.GenerateContentConfig(
                                        temperature=0.3,
                                        system_instruction=[types.Part.from_text(text=secondary_system)],
                                    )
                                    result_parts = []
                                    for chunk in client_secondary.models.generate_content_stream(
                                        model='gemini-2.5-flash-lite',  # faster for this task  
                                        contents=contents_secondary,
                                        config=cfg_secondary,
                                    ):
                                        if getattr(chunk, "text", None):
                                            result_parts.append(chunk.text)
                                    custom_text = _clean_markdown_response("".join(result_parts).strip())
                                    if not custom_text:
                                        st.error("A IA n√£o retornou um modelo customizado.")
                                    else:
                                        st.session_state.custom_template_text = custom_text
                                        st.session_state.custom_template_source_name = uploaded_custom_model.name
                                        st.success("Modelo customizado gerado e armazenado para uso.")
                                except Exception as sec_exc:
                                    st.error(f"Falha ao gerar modelo customizado: {sec_exc}")
                finally:
                    # Remove loader in any case
                    loader.empty()

            if st.session_state.custom_template_text:
                with st.expander("Pr√©-visualiza√ß√£o do modelo customizado ativo", expanded=False):
                    st.text_area("Modelo customizado", value=st.session_state.custom_template_text, height=300)
                    if st.button("Descartar modelo customizado"):
                        st.session_state.custom_template_text = ""
                        st.session_state.custom_template_source_name = ""
                        st.info("Modelo customizado descartado. Voltando ao modelo interno selecionado.")

        st.markdown("---")
        st.subheader("Informa√ß√µes adicionais")
        st.text_area(
            "Notas para a IA (opcional)",
            key="extra_notes",
            placeholder="Ex.: 'A etapa 3 agora √© automatizada pela √°rea X' ou 'N√£o incluir o processo manual antigo'.",
            help="Use este campo para passar contextos espec√≠ficos que devem ser incorporados na documenta√ß√£o gerada.",
            height=150,
        )

    # Render modal AFTER sidebar (so first click works)
    if st.session_state.layout_modal_open:
        modal_fn = getattr(st, "modal", None)
        dialog_fn = getattr(st, "dialog", None)
        exp_dialog_fn = getattr(st, "experimental_dialog", None)

        if callable(modal_fn):
            with modal_fn("Configurar layout do documento", key="layout-config-modal"):
                _render_layout_config_body(workdir, "_modal")
        elif callable(dialog_fn) or callable(exp_dialog_fn):
            dialog_callable = dialog_fn if callable(dialog_fn) else exp_dialog_fn

            @dialog_callable("Configurar layout do documento")
            def _layout_dialog():
                _render_layout_config_body(workdir, "_dialog")

            _layout_dialog()
        else:
            st.markdown(
                """
                <style>
                .layout-config-backdrop { position: fixed; inset: 0; background: rgba(0,0,0,0.55); z-index: 995; }
                .layout-config-panel { position: fixed; top: 5%; left: 50%; transform: translateX(-50%);
                    width: min(900px, 95%); max-height: 90vh; overflow-y: auto; background: #111827;
                    color: #e5e7eb; border-radius: 12px; padding: 24px 28px; z-index: 996; border: 1px solid #1f2937; }
                .layout-config-panel h3 { margin-top: 0; }
                </style>
                <div class=\"layout-config-backdrop\"></div>
                <div class=\"layout-config-panel\">
                """,
                unsafe_allow_html=True,
            )
            st.markdown("### Configurar layout do documento")
            _render_layout_config_body(workdir, "_fallback")
            st.markdown("</div>", unsafe_allow_html=True)
            st.caption("Atualize o Streamlit para uma vers√£o mais recente para usar modais nativos.")
    # Metadados removidos conforme solicitado

    # Main: Uploads
    st.markdown("### Entradas")
    video_file = st.file_uploader("V√≠deo (obrigat√≥rio)", type=["mp4", "mov", "avi", "mkv", "webm"], accept_multiple_files=False)
    transcript_file = st.file_uploader("Transcri√ß√£o (opcional: .vtt ou .txt)", type=["vtt", "txt"], accept_multiple_files=False)
    uploaded_md = st.file_uploader("Arquivo .md (opcional: usar este no lugar da IA)", type=["md"], accept_multiple_files=False)

    st.write("")
    generate_btn = st.button("Gerar documenta√ß√£o DOCX", type="primary", use_container_width=True)

    _help_modal()

    if generate_btn:
        # Valida√ß√µes
        if not api_key:
            st.error("Informe a Gemini API Key na barra lateral.")
            return
        if not video_file:
            st.error("Envie um arquivo de v√≠deo.")
            return
        try:
            video_bytes = video_file.read()
            video_mime = _detect_mime(video_file.name)
            transcript_bytes = transcript_file.read() if transcript_file else None
            transcript_mime = _detect_mime(transcript_file.name) if transcript_file else None

            with st.status("Processando documenta√ß√£o...", state="running") as status:
                out_dir = _get_output_dir()
                # 1/3: Preparar v√≠deo (usar bytes diretamente se upload, ou path se fornecido)
                status.write("1/3 ‚Ä¢ Preparando v√≠deo...")
                try:
                    size_mb = (len(video_bytes) / (1024*1024)) if video_bytes else 0
                    status.write(f"Tamanho do v√≠deo: {size_mb:.1f} MB. O upload/processamento pela IA pode levar alguns minutos‚Ä¶")
                except Exception:
                    size_mb = 0
                # Preparar v√≠deo em temp se necess√°rio para extra√ß√£o de prints
                video_temp_path = None
                if video_bytes:
                    # Upload: salvar em temp
                    import tempfile
                    with tempfile.NamedTemporaryFile(suffix=Path(video_file.name).suffix if video_file else ".mp4", delete=False) as tmp:
                        tmp.write(video_bytes)
                        video_temp_path = Path(tmp.name)
                elif st.session_state.input_video_path:
                    # Path fornecido: usar diretamente
                    video_temp_path = Path(st.session_state.input_video_path)
                    if not video_temp_path.exists():
                        status.update(label=f"Arquivo de v√≠deo n√£o encontrado: {video_temp_path}", state="error")
                        return
                else:
                    status.update(label="V√≠deo n√£o fornecido.", state="error")
                    return

                # 2/3: Obter .md (IA ou arquivo enviado)
                if uploaded_md is not None:
                    status.write("2/3 ‚Ä¢ Carregando .md fornecido...")
                    try:
                        md_text = uploaded_md.read().decode("utf-8", errors="ignore")
                    except Exception as dec_exc:
                        status.update(label=f"Falha ao ler o .md enviado: {dec_exc}", state="error")
                        return
                    st.session_state.generated_md = _clean_markdown_response(md_text)
                else:
                    status.write("2/3 ‚Ä¢ Gerando o .md com a IA...")
                    # Choose active template: if 'Customizado' selected and custom exists, use it;
                    # otherwise use the selected internal template (fallback to model_rpa)
                    if st.session_state.internal_template_key == "Customizado" and st.session_state.custom_template_text.strip():
                        selected_template_text = st.session_state.custom_template_text.strip()
                    else:
                        # Build internal map again (guards against code moves)
                        internal_template_map = {
                            name: getattr(internal_models, name)
                            for name in dir(internal_models)
                            if name.startswith("model_") and isinstance(getattr(internal_models, name), str)
                        }
                        key = st.session_state.internal_template_key if st.session_state.internal_template_key != "Customizado" else ("model_rpa" if "model_rpa" in internal_template_map else (next(iter(internal_template_map.keys()), "")))
                        selected_template_text = internal_template_map.get(key, "")
                    md = run_generation(
                        api_key=api_key,
                        video_name=video_file.name if video_file else "video.mp4",
                        video_mime=video_mime,
                        video_path=video_temp_path,
                        video_bytes=video_bytes,
                        video_size_mb=float(size_mb) if size_mb else None,
                        transcript_name=(transcript_file.name if transcript_file else None),
                        transcript_bytes=transcript_bytes,
                        transcript_mime=transcript_mime,
                        progress=lambda msg: status.write(msg),
                        extra_notes=(st.session_state.extra_notes.strip() or None),
                        active_template_text=selected_template_text,
                    )
                    st.session_state.generated_md = _clean_markdown_response(md)
                # N√£o salvar .md em arquivo; manter em mem√≥ria

                _write_doc_metadata(
                    out_dir,
                    st.session_state.doc_elaboracao.strip(),
                    st.session_state.doc_aprovacao.strip(),
                )

                # Preparar assets de layout em diret√≥rio tempor√°rio (n√£o salvar no projeto)
                def _prepare_layout_temp_dir() -> Optional[Path]:
                    tmp_dir = Path(tempfile.mkdtemp(prefix="layout_assets_"))
                    wrote = False
                    try:
                        if st.session_state.get("layout_logo_data"):
                            name = st.session_state.get("layout_logo_filename") or "logo.png"
                            (tmp_dir / f"logo_{name}").write_bytes(st.session_state["layout_logo_data"])
                            wrote = True
                        if st.session_state.get("layout_separator_data"):
                            name = st.session_state.get("layout_separator_filename") or "separator.png"
                            (tmp_dir / f"separator_{name}").write_bytes(st.session_state["layout_separator_data"])
                            wrote = True
                        if st.session_state.get("layout_footer_banner_data"):
                            name = st.session_state.get("layout_footer_banner_filename") or "footer.png"
                            (tmp_dir / f"footer_{name}").write_bytes(st.session_state["layout_footer_banner_data"])
                            wrote = True
                        # Opcional: salvar JSON informativo
                        cfg = {
                            "company_name": st.session_state.get("layout_company_name", ""),
                            "logo_filename": st.session_state.get("layout_logo_filename"),
                            "separator_filename": st.session_state.get("layout_separator_filename"),
                            "footer_banner_filename": st.session_state.get("layout_footer_banner_filename"),
                        }
                        (tmp_dir / "layout_config.json").write_text(json.dumps(cfg, ensure_ascii=False, indent=2), encoding="utf-8")
                    except Exception:
                        pass
                    if wrote:
                        return tmp_dir
                    try:
                        shutil.rmtree(tmp_dir, ignore_errors=True)
                    except Exception:
                        pass
                    return None
                layout_tmp_dir = _prepare_layout_temp_dir()

                # 3/3: Rodar formata√ß√£o DOCX
                status.write("3/3 ‚Ä¢ Formatando DOCX (pode levar alguns minutos)...")
                generator_script = out_dir / "Captura" / "CriadorDocumenta√ß√£o.py"
                if not generator_script.exists():
                    status.update(label="CriadorDocumenta√ß√£o.py n√£o encontrado em Gera√ß√£oDOc.", state="error")
                    return

                env = os.environ.copy()
                env["INPUT_VIDEO_PATH"] = str(video_temp_path)
                if layout_tmp_dir and layout_tmp_dir.exists():
                    env["LAYOUT_ASSETS_DIR"] = str(layout_tmp_dir)
                # Usar diret√≥rio tempor√°rio para outputs
                with tempfile.TemporaryDirectory() as temp_output_dir:
                    env["OUTPUT_DIR"] = temp_output_dir
                    try:
                        proc = subprocess.run(
                            [sys.executable, str(generator_script)],
                            cwd=str(out_dir),
                            env=env,
                            input=st.session_state.generated_md.encode('utf-8'),  # Passar md como bytes via stdin
                            capture_output=True,
                            text=False,  # Para capturar bytes
                            timeout=1800,
                        )
                    except Exception as ex:
                        status.update(label=f"Falha ao executar o gerador de DOCX: {ex}", state="error")
                        return

                    if proc.returncode != 0:
                        status.update(label="Falha ao gerar o DOCX.", state="error")
                        st.code((proc.stdout.decode('utf-8', errors='ignore') or "") + "\n" + (proc.stderr.decode('utf-8', errors='ignore') or ""), language="bash")
                        return

                    # DOCX vem via stdout como bytes
                    docx_bytes = proc.stdout
                    if not docx_bytes:
                        status.update(label="DOCX n√£o gerado.", state="error")
                        return
                    st.session_state.last_docx_bytes = docx_bytes
                    st.session_state.last_docx_b64 = base64.b64encode(docx_bytes).decode("ascii")
                    st.session_state.last_docx_name = "documento.docx"
                    st.session_state.trigger_download = True
                    st.session_state.download_data_url = ""
                    status.update(label="Conclu√≠do! Iniciando download do DOCX...", state="complete")

                # Atualiza hist√≥rico do chat (resumo)
                st.session_state.chat_history.append({"role": "user", "text": f"Solicita√ß√£o inicial com v√≠deo '{video_file.name}'"})
                if st.session_state.extra_notes.strip():
                    st.session_state.chat_history.append({"role": "user", "text": f"Notas adicionais: {st.session_state.extra_notes.strip()}"})
                st.session_state.chat_history.append({"role": "ia", "text": "Documento .md gerado e formatado em DOCX (vers√£o 1)."})
        except Exception as e:
            st.error(f"Falha ao gerar: {e}")

    # Se um DOCX foi gerado, dispara (uma vez) o download autom√°tico e exibe mensagem de fallback
    if st.session_state.last_docx_bytes:
        if st.session_state.trigger_download:
            try:
                st.session_state.download_data_url = _auto_download_docx(
                    st.session_state.last_docx_name,
                    st.session_state.last_docx_bytes,
                )
            finally:
                st.session_state.trigger_download = False
        if st.session_state.download_data_url:
            st.markdown(
                f"""
                <div style="margin-top:12px;text-align:center;font-size:13px;opacity:0.85;">
                    Se o download n√£o iniciar automaticamente,
                    <a href="{st.session_state.download_data_url}" download="{st.session_state.last_docx_name}">clique aqui para baixar o DOCX</a>.
                </div>
                """,
                unsafe_allow_html=True,
            )

    # Campo de altera√ß√µes p√≥s-gera√ß√£o
    if st.session_state.generated_md:
        st.markdown("---")
        st.subheader("Solicitar altera√ß√µes no documento")
        change_text = st.text_area("Descreva as altera√ß√µes desejadas", placeholder="Ex.: Trocar o t√≠tulo, incluir uma observa√ß√£o na etapa 2, corrigir o timestamp do print X para 00:04:12...")
        apply_changes = st.button("Aplicar altera√ß√µes e gerar novo DOCX", use_container_width=True)

        if apply_changes and change_text.strip():
            # Regerar o .md com base no atual + instru√ß√µes
            api_key = os.environ.get("GEMINI_API_KEY", "")
            if not api_key:
                st.error("Informe a Gemini API Key na barra lateral.")
                return

            with st.status("Aplicando altera√ß√µes e formatando novo DOCX...", state="running") as status:
                status.write("1/3 ‚Ä¢ Pedindo revis√£o do .md √† IA...")
                client = genai.Client(api_key=api_key)
                revised_prompt = (
                    "Aplique as altera√ß√µes abaixo ao documento Markdown a seguir, mantendo TODAS as regras do padr√£o R004 e respondendo apenas com o .md completo atualizado.\n\n"
                    f"Altera√ß√µes solicitadas:\n{change_text}\n\n"
                    f"Documento atual (.md):\n\n{st.session_state.generated_md}"
                )
                extra_context = st.session_state.extra_notes.strip()
                if extra_context:
                    revised_prompt += (
                        "\n\nInforma√ß√µes adicionais fornecidas originalmente (mantenha consistentes no resultado):\n"
                        f"{extra_context}"
                    )
                contents = [types.Content(role="user", parts=[types.Part.from_text(text=revised_prompt)])]
                cfg = types.GenerateContentConfig(
                    temperature=0.4,
                    thinking_config=types.ThinkingConfig(thinking_budget=-1),
                    system_instruction=[types.Part.from_text(text=build_system_instruction())],
                )

                try:
                    output_md = []
                    try:
                        for chunk in client.models.generate_content_stream(
                            model=MODEL_ID,
                            contents=contents,
                            config=cfg,
                        ):
                            if getattr(chunk, "text", None):
                                output_md.append(chunk.text)
                    except genai_errors.ServerError as exc:  # type: ignore[attr-defined]
                        error_code = getattr(exc, "status_code", None) or getattr(exc, "code", None)
                        if error_code == 503:
                            wait_seconds = 6
                            status.write(
                                "O modelo est√° sobrecarregado (503). Aguardando alguns segundos antes de tentar novamente em modo n√£o streaming..."
                            )
                            time.sleep(wait_seconds)
                            resp = client.models.generate_content(
                                model=MODEL_ID,
                                contents=contents,
                                config=cfg,
                            )
                            text = _safe_extract_text(resp)
                            if not text:
                                raise RuntimeError("Resposta vazia da IA ap√≥s fallback n√£o-streaming.") from exc
                            output_md = [text]
                        else:
                            raise

                    if not output_md:
                        raise RuntimeError("A IA n√£o retornou conte√∫do ap√≥s as tentativas de revis√£o.")

                    st.session_state.generated_md = _clean_markdown_response("".join(output_md))
                except Exception as gen_error:
                    status.update(label=f"Falha ao gerar revis√£o do .md: {gen_error}", state="error")
                    st.error(f"Falha ao revisar o documento: {gen_error}")
                    return

                out_dir = _get_output_dir()
                # N√£o salvar .md

                _write_doc_metadata(
                    out_dir,
                    st.session_state.doc_elaboracao.strip(),
                    st.session_state.doc_aprovacao.strip(),
                )
                # Preparar assets de layout em diret√≥rio tempor√°rio (n√£o salvar no projeto)
                def _prepare_layout_temp_dir2() -> Optional[Path]:
                    tmp_dir = Path(tempfile.mkdtemp(prefix="layout_assets_"))
                    wrote = False
                    try:
                        if st.session_state.get("layout_logo_data"):
                            name = st.session_state.get("layout_logo_filename") or "logo.png"
                            (tmp_dir / f"logo_{name}").write_bytes(st.session_state["layout_logo_data"])
                            wrote = True
                        if st.session_state.get("layout_separator_data"):
                            name = st.session_state.get("layout_separator_filename") or "separator.png"
                            (tmp_dir / f"separator_{name}").write_bytes(st.session_state["layout_separator_data"])
                            wrote = True
                        if st.session_state.get("layout_footer_banner_data"):
                            name = st.session_state.get("layout_footer_banner_filename") or "footer.png"
                            (tmp_dir / f"footer_{name}").write_bytes(st.session_state["layout_footer_banner_data"])
                            wrote = True
                        cfg = {
                            "company_name": st.session_state.get("layout_company_name", ""),
                            "logo_filename": st.session_state.get("layout_logo_filename"),
                            "separator_filename": st.session_state.get("layout_separator_filename"),
                            "footer_banner_filename": st.session_state.get("layout_footer_banner_filename"),
                        }
                        (tmp_dir / "layout_config.json").write_text(json.dumps(cfg, ensure_ascii=False, indent=2), encoding="utf-8")
                    except Exception:
                        pass
                    if wrote:
                        return tmp_dir
                    try:
                        shutil.rmtree(tmp_dir, ignore_errors=True)
                    except Exception:
                        pass
                    return None
                layout_tmp_dir2 = _prepare_layout_temp_dir2()

                status.write("2/3 ‚Ä¢ Formatando novo DOCX...")
                generator_script = out_dir / "Captura" / "CriadorDocumenta√ß√£o.py"
                env = os.environ.copy()
                env["INPUT_VIDEO_PATH"] = str(video_temp_path)  # Usar o v√≠deo temp
                if layout_tmp_dir2 and layout_tmp_dir2.exists():
                    env["LAYOUT_ASSETS_DIR"] = str(layout_tmp_dir2)
                # Usar diret√≥rio tempor√°rio para outputs
                with tempfile.TemporaryDirectory() as temp_output_dir:
                    env["OUTPUT_DIR"] = temp_output_dir
                    try:
                        proc = subprocess.run(
                            [sys.executable, str(generator_script)],
                            cwd=str(out_dir),
                            env=env,
                            input=st.session_state.generated_md.encode('utf-8'),  # Passar md como bytes via stdin
                            capture_output=True,
                            text=False,  # Capturar bytes
                            timeout=1800,
                        )
                    except Exception as ex:
                        status.update(label=f"Falha ao executar o gerador de DOCX revisado: {ex}", state="error")
                        return

                    if proc.returncode != 0:
                        status.update(label="Falha ao gerar o DOCX revisado.", state="error")
                        st.code((proc.stdout.decode('utf-8', errors='ignore') or "") + "\n" + (proc.stderr.decode('utf-8', errors='ignore') or ""), language="bash")
                        return

                    # DOCX vem via stdout
                    docx_bytes = proc.stdout
                    if not docx_bytes:
                        status.update(label="DOCX revisado n√£o gerado.", state="error")
                        return
                    st.session_state.last_docx_bytes = docx_bytes
                    st.session_state.last_docx_b64 = base64.b64encode(docx_bytes).decode("ascii")
                    st.session_state.last_docx_name = "documento_revisado.docx"
                    st.session_state.trigger_download = True
                st.session_state.download_data_url = ""
                status.update(label="Conclu√≠do! Iniciando download do DOCX revisado...", state="complete")

                st.session_state.chat_history.append({"role": "user", "text": change_text})
                st.session_state.chat_history.append({"role": "ia", "text": "Documento atualizado e DOCX reformatado."})

                st.experimental_rerun()

        # Hist√≥rico de conversa (compacto)
        if st.session_state.chat_history:
            st.markdown("### Hist√≥rico da conversa")
            for msg in st.session_state.chat_history[-20:]:
                prefix = "Voc√™" if msg["role"] == "user" else "IA"
                st.markdown(f"- **{prefix}:** {msg['text']}")


if __name__ == "__main__":
    main()
